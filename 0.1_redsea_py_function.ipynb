{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDSEA python version 0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translated from Yunhao Bai's MATLAB code by Bokai Zhu.\n",
    "\n",
    "Some minor difference with Yunhao's MATLAB (subject to update in future version):\n",
    "\n",
    "1. Does not filter the positive nuclear identity (cells) (because that part of code is in \"mibisegmentByDeepProbWithPerm3.m\"). But can be easily added by user.\n",
    "\n",
    "2. Does not produce the sanity plot, since it should be outside of the compensation function. OPTIONAL add later\n",
    "\n",
    "3. Does not produce FCS file at the end. Instead produce the 4 fcs file in a matrix style (pandas format), easier for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import concurrent.futures\n",
    "# import itertools\n",
    "import pathlib\n",
    "\n",
    "# import zipfile\n",
    "# from typing import Optional, Union, Iterable, Tuple\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tifffile\n",
    "# import zarr\n",
    "# from numcodecs import Blosc\n",
    "# from skimage.measure import regionprops_table\n",
    "# necessary packages\n",
    "import PIL\n",
    "from PIL import Image, ImageSequence, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "import glob\n",
    "import time\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "\n",
    "from utils import imshow, side_by_side, plot_co_expression\n",
    "from utils import intensity_change_at_cell_level\n",
    "from SingleCellDataExtraction import MaskZstack\n",
    "\n",
    "# helper function 1\n",
    "\n",
    "\n",
    "def ismember(a, b):\n",
    "    bind = {}\n",
    "    for i, elt in enumerate(b):\n",
    "        if elt not in bind:\n",
    "            bind[elt] = i\n",
    "    return [\n",
    "        bind.get(itm, None) for itm in a\n",
    "    ]  # None can be replaced by any other \"not in b\" value\n",
    "\n",
    "\n",
    "# helper function 2\n",
    "\n",
    "\n",
    "def printProgressBar(\n",
    "    iteration,\n",
    "    total,\n",
    "    prefix=\"\",\n",
    "    suffix=\"\",\n",
    "    decimals=1,\n",
    "    length=100,\n",
    "    fill=\"█\",\n",
    "    printEnd=\"\\r\",\n",
    "):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + \"-\" * (length - filledLength)\n",
    "    print(f\"\\r{prefix} |{bar}| {percent}% {suffix}\", end=printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()\n",
    "\n",
    "\n",
    "def run_redsea(\n",
    "    tiff,\n",
    "    seg_mask,\n",
    "    markers_csv,\n",
    "    markers_of_interest,\n",
    "    output_dir,\n",
    "    boundary_mode=2,  # Ignored atm\n",
    "    compensation_mode=1,\n",
    "    element_shape=2,\n",
    "    element_size=2,\n",
    "):\n",
    "    # parameters for compensation\n",
    "    # boundary_mode = boundaryMod = 2 # 2 means boundary, 1 whole cell\n",
    "    # compensation_mode = REDSEAChecker = 1 # 1 means subtract+ reinforce\n",
    "    # element_shape = elementShape = 2 # star, 1 == square size\n",
    "    # element_size = elementSize = 2 # star or square extension size\n",
    "    massDS = pd.read_csv(markers_csv)  # read the mass csv\n",
    "    if massDS.columns.values[0] != \"marker_name\":\n",
    "        massDS = pd.read_csv(markers_csv, header=None)\n",
    "        massDS.columns = [\"marker_name\"]\n",
    "\n",
    "    # remove the wavelenth\n",
    "    markers = []\n",
    "    for m in massDS.marker_name:\n",
    "        for s in [\"_488\", \"_555\", \"_570\", \"_647\", \"_660\"]:\n",
    "            m = m.replace(s, \"\")\n",
    "        markers.append(m)\n",
    "    massDS[\"marker_name\"] = markers\n",
    "\n",
    "    normChannels = markers_of_interest\n",
    "    #### should be inside the function\n",
    "    normChannelsInds = ismember(normChannels, massDS[\"marker_name\"])\n",
    "    channelNormIdentity = np.zeros((len(massDS[\"marker_name\"]), 1))\n",
    "    # make a flag for compensation\n",
    "    for i in range(len(normChannelsInds)):\n",
    "        channelNormIdentity[normChannelsInds[i]] = 1\n",
    "\n",
    "    clusterChannels = massDS[\"marker_name\"]  # only get the label column\n",
    "    clusterChannelsInds = np.where(np.isin(clusterChannels, massDS[\"marker_name\"]))[\n",
    "        0\n",
    "    ]  # channel indexes\n",
    "\n",
    "    tiff_img = imread(tiff)\n",
    "\n",
    "    countsNoNoise = np.swapaxes(np.swapaxes(tiff_img, 0, 1), 1, 2)\n",
    "\n",
    "    segMat = imread(seg_mask)\n",
    "\n",
    "    # rename the labels as this is a subset from the full sample\n",
    "    lb = 0\n",
    "    for i in sorted(np.unique(segMat)):\n",
    "        segMat = np.where(segMat == i, lb, segMat)\n",
    "        lb += 1\n",
    "\n",
    "    labelNum = np.max(segMat)\n",
    "    stats = skimage.measure.regionprops(segMat)\n",
    "    newLmod = segMat\n",
    "\n",
    "    ##### stuff related to mat finisehd\n",
    "    channelNum = len(clusterChannels)  # how many channels\n",
    "\n",
    "    data = np.zeros((labelNum, channelNum))\n",
    "    dataScaleSize = np.zeros((labelNum, channelNum))\n",
    "    cellSizes = np.zeros((labelNum, 1))\n",
    "\n",
    "    centroid_xs = []\n",
    "    centroid_ys = []\n",
    "\n",
    "    for i in range(labelNum):  # for each cell (label)\n",
    "        label_counts = [\n",
    "            countsNoNoise[coord[0], coord[1], :] for coord in stats[i].coords\n",
    "        ]  # all channel count for this cell\n",
    "        data[i, 0:channelNum] = np.sum(\n",
    "            label_counts, axis=0\n",
    "        )  #  sum the counts for this cell\n",
    "        dataScaleSize[i, 0:channelNum] = (\n",
    "            np.sum(label_counts, axis=0) / stats[i].area\n",
    "        )  # scaled by size\n",
    "        cellSizes[i] = stats[i].area  # cell sizes\n",
    "        centroid_xs.append(stats[i].centroid[0])\n",
    "        centroid_ys.append(stats[i].centroid[1])\n",
    "\n",
    "    [rowNum, colNum] = newLmod.shape\n",
    "    cellNum = labelNum\n",
    "    cellPairMap = np.zeros(\n",
    "        (cellNum, cellNum)\n",
    "    )  # cell-cell shared perimeter matrix container\n",
    "\n",
    "    ## need to add border to the segmentation mask (newLmod in this case)\n",
    "    newLmod_border = np.pad(newLmod, pad_width=1, mode=\"constant\", constant_values=0)\n",
    "\n",
    "    # start looping the mask and produce the cell-cell contact matrix\n",
    "    for i in range(rowNum):\n",
    "        for j in range(colNum):\n",
    "            if newLmod[i, j] == 0:\n",
    "                tempMatrix = newLmod_border[\n",
    "                    i : i + 3, j : j + 3\n",
    "                ]  # the 3x3 window, xy shifted +1 due to border\n",
    "                tempFactors = np.unique(tempMatrix)  # unique\n",
    "                tempFactors = tempFactors - 1  # minus one for python index\n",
    "                if len(tempFactors) == 3:  # means only two cells\n",
    "                    cellPairMap[tempFactors[1], tempFactors[2]] = (\n",
    "                        cellPairMap[tempFactors[1], tempFactors[2]] + 1\n",
    "                    )  # count zero\n",
    "                elif len(tempFactors) == 4:  # means three cells, three pairs\n",
    "                    cellPairMap[tempFactors[1], tempFactors[2]] = (\n",
    "                        cellPairMap[tempFactors[1], tempFactors[2]] + 1\n",
    "                    )  # count zero\n",
    "                    cellPairMap[tempFactors[1], tempFactors[3]] = (\n",
    "                        cellPairMap[tempFactors[1], tempFactors[3]] + 1\n",
    "                    )  # count zero\n",
    "                    cellPairMap[tempFactors[2], tempFactors[3]] = (\n",
    "                        cellPairMap[tempFactors[2], tempFactors[3]] + 1\n",
    "                    )  # count zero\n",
    "                elif len(tempFactors) == 5:  # means four cells, 6 pairs\n",
    "                    cellPairMap[tempFactors[1], tempFactors[2]] = (\n",
    "                        cellPairMap[tempFactors[1], tempFactors[2]] + 1\n",
    "                    )  # count zero\n",
    "                    cellPairMap[tempFactors[1], tempFactors[3]] = (\n",
    "                        cellPairMap[tempFactors[1], tempFactors[3]] + 1\n",
    "                    )  # count zero\n",
    "                    cellPairMap[tempFactors[1], tempFactors[4]] = (\n",
    "                        cellPairMap[tempFactors[1], tempFactors[4]] + 1\n",
    "                    )  # count zero\n",
    "\n",
    "                    cellPairMap[tempFactors[2], tempFactors[3]] = (\n",
    "                        cellPairMap[tempFactors[2], tempFactors[3]] + 1\n",
    "                    )  # count zero\n",
    "                    cellPairMap[tempFactors[2], tempFactors[4]] = (\n",
    "                        cellPairMap[tempFactors[2], tempFactors[4]] + 1\n",
    "                    )  # count zero\n",
    "\n",
    "                    cellPairMap[tempFactors[3], tempFactors[4]] = (\n",
    "                        cellPairMap[tempFactors[3], tempFactors[4]] + 1\n",
    "                    )  # count zero\n",
    "\n",
    "    # double direction\n",
    "    cellPairMap = cellPairMap + np.transpose(cellPairMap)\n",
    "\n",
    "    ###############\n",
    "    cellBoundaryTotal = np.sum(cellPairMap, axis=0)  # count the boundary\n",
    "    ############### this step might cause error in ark version, double check with YH\n",
    "\n",
    "    # devide to get fraction\n",
    "    cellBoundaryTotalMatrix = np.tile(cellBoundaryTotal, (cellNum, 1))\n",
    "    # cellBoundaryTotalMatrix = repmat(cellBoundaryTotal',[1 cellNum]);\n",
    "    cellPairNorm = (\n",
    "        compensation_mode * np.identity(cellNum) - cellPairMap / cellBoundaryTotalMatrix\n",
    "    )\n",
    "    cellPairNorm = np.transpose(\n",
    "        cellPairNorm\n",
    "    )  ### this is a werid bug in python, need to transpose\n",
    "    # now starts the calculation of signals from pixels along the boudnary of cells\n",
    "    MIBIdataNearEdge1 = np.zeros((cellNum, channelNum))\n",
    "\n",
    "    ##### A List of Items\n",
    "    items = list(range(cellNum))\n",
    "    l = len(items)\n",
    "    printProgressBar(\n",
    "        0, l, prefix=\"Progress:\", suffix=\"Complete\", length=50\n",
    "    )  # progress bar\n",
    "    #####\n",
    "\n",
    "    ######pre-calculated shape\n",
    "    if element_shape == 1:  # square\n",
    "        square = skimage.morphology.square(2 * element_size + 1)\n",
    "        square_loc = np.where(square == 1)\n",
    "    elif element_shape == 2:  # diamond\n",
    "        diam = skimage.morphology.diamond(\n",
    "            element_size\n",
    "        )  # create diamond shapte based on elementSize\n",
    "        diam_loc = np.where(diam == 1)\n",
    "    else:\n",
    "        print(\"Error elementShape Value not recognized.\")\n",
    "    ############\n",
    "\n",
    "    for i in range(cellNum):\n",
    "        label = i + 1  # python problem\n",
    "        [tempRow, tempCol] = np.where(newLmod == label)\n",
    "        # sequence in row not col, should not affect the code\n",
    "        for j in range(len(tempRow)):\n",
    "            label_in_shape = []  # empy list in case\n",
    "            # make sure not expand outside\n",
    "            if (\n",
    "                (element_size - 1 < tempRow[j])\n",
    "                and (tempRow[j] < rowNum - element_size - 2)\n",
    "                and (element_size - 1 < tempCol[j])\n",
    "                and (tempCol[j] < colNum - element_size - 2)\n",
    "            ):\n",
    "                ini_point = [\n",
    "                    tempRow[j] - element_size,\n",
    "                    tempCol[j] - element_size,\n",
    "                ]  # corrected top-left point\n",
    "\n",
    "                if element_shape == 1:  # square\n",
    "                    square_loc_ini_x = [item + ini_point[0] for item in square_loc[0]]\n",
    "                    square_loc_ini_y = [item + ini_point[1] for item in square_loc[1]]\n",
    "\n",
    "                    label_in_shape = [\n",
    "                        newLmod[square_loc_ini_x[k], square_loc_ini_y[k]]\n",
    "                        for k in range(len(square_loc_ini_x))\n",
    "                    ]\n",
    "\n",
    "                elif element_shape == 2:  # diamond\n",
    "                    diam_loc_ini_x = [item + ini_point[0] for item in diam_loc[0]]\n",
    "                    diam_loc_ini_y = [item + ini_point[1] for item in diam_loc[1]]\n",
    "                    # finish add to ini point\n",
    "\n",
    "                    label_in_shape = [\n",
    "                        newLmod[diam_loc_ini_x[k], diam_loc_ini_y[k]]\n",
    "                        for k in range(len(diam_loc_ini_x))\n",
    "                    ]\n",
    "\n",
    "            if 0 in label_in_shape:\n",
    "                MIBIdataNearEdge1[i, :] = (\n",
    "                    MIBIdataNearEdge1[i, :] + countsNoNoise[tempRow[j], tempCol[j], :]\n",
    "                )\n",
    "\n",
    "        # Update Progress Bar\n",
    "        printProgressBar(i + 1, l, prefix=\"Progress:\", suffix=\"Complete\", length=50)\n",
    "\n",
    "    ## fome final formatting\n",
    "\n",
    "    MIBIdataNorm2 = np.transpose(np.dot(np.transpose(MIBIdataNearEdge1), cellPairNorm))\n",
    "    # this is boundary signal subtracted by cell neighboor boundary\n",
    "    MIBIdataNorm2 = (\n",
    "        MIBIdataNorm2 + data\n",
    "    )  # reinforce onto the whole cell signal (original signal)\n",
    "    MIBIdataNorm2[MIBIdataNorm2 < 0] = 0  # clear out the negative ones\n",
    "    # flip the channelNormIdentity for calculation\n",
    "    rev_channelNormIdentity = np.ones_like(channelNormIdentity) - channelNormIdentity\n",
    "    # composite the normalized channels with non-normalized channels\n",
    "    # MIBIdataNorm2 is the matrix to return\n",
    "    MIBIdataNorm2 = data * np.transpose(\n",
    "        np.tile(rev_channelNormIdentity, (1, cellNum))\n",
    "    ) + MIBIdataNorm2 * np.transpose(np.tile(channelNormIdentity, (1, cellNum)))\n",
    "    # scale by size\n",
    "    dataCompenScaleSize = MIBIdataNorm2 / cellSizes\n",
    "    # some last steps\n",
    "    ############ SKIP THE POSITIVE NUCLEAR IDENTITY FILTER\n",
    "    ############ SHOULD ADD by user's choice\n",
    "\n",
    "    labelIdentityNew2 = np.ones(cellNum)  ####### this part is the skipped line\n",
    "    sumDataScaleSizeInClusterChannels = np.sum(\n",
    "        dataScaleSize[:, clusterChannelsInds], axis=1\n",
    "    )  # add all the cluster channels\n",
    "    labelIdentityNew2[\n",
    "        sumDataScaleSizeInClusterChannels < 0.1\n",
    "    ] = 2  # remove the cells that does not have info in cluster channels\n",
    "    # the function should return 4 varaibles\n",
    "    # matrix\n",
    "    dataCells = data[labelIdentityNew2 == 1, :]\n",
    "    dataScaleSizeCells = dataScaleSize[labelIdentityNew2 == 1, :]\n",
    "    dataCompenCells = MIBIdataNorm2[labelIdentityNew2 == 1, :]\n",
    "    dataCompenScaleSizeCells = dataCompenScaleSize[labelIdentityNew2 == 1, :]\n",
    "\n",
    "    # create the final matrixs ( 4 types of them)\n",
    "\n",
    "    labelVec = np.where(labelIdentityNew2 == 1)\n",
    "    labelVec = [\n",
    "        item + 1 for item in labelVec\n",
    "    ]  # python indexing difference need to add 1\n",
    "\n",
    "    # get cell sizes\n",
    "    cellSizesVec = cellSizes[labelIdentityNew2 == 1].flatten()\n",
    "\n",
    "    # produce the matrices\n",
    "\n",
    "    ## first dataframe\n",
    "    dataL = pd.DataFrame({\"CellID\": labelVec[0].tolist(), \"cell_size\": cellSizesVec})\n",
    "    dataCells_df = pd.DataFrame(dataCells)\n",
    "    dataCells_df.columns = clusterChannels\n",
    "    dataL_full = pd.concat((dataL, dataCells_df), axis=1)\n",
    "    ### second\n",
    "    dataScaleSizeL_df = pd.DataFrame(dataScaleSizeCells)\n",
    "    dataScaleSizeL_df.columns = clusterChannels\n",
    "    dataScaleSizeL_full = pd.concat((dataL, dataScaleSizeL_df), axis=1)\n",
    "    ### third\n",
    "    dataCompenL_df = pd.DataFrame(dataCompenCells)\n",
    "    dataCompenL_df.columns = clusterChannels\n",
    "    dataCompenL_full = pd.concat((dataL, dataCompenL_df), axis=1)\n",
    "    ### forth\n",
    "    dataCompenScaleSizeL_df = pd.DataFrame(dataCompenScaleSizeCells)\n",
    "    dataCompenScaleSizeL_df.columns = clusterChannels\n",
    "    dataCompenScaleSizeL_full = pd.concat((dataL, dataCompenScaleSizeL_df), axis=1)\n",
    "\n",
    "    for d in [\n",
    "        dataL_full,\n",
    "        dataScaleSizeL_full,\n",
    "        dataCompenL_full,\n",
    "        dataCompenScaleSizeL_full,\n",
    "    ]:\n",
    "        d[\"x_centroid\"] = centroid_xs\n",
    "        d[\"y_centroid\"] = centroid_ys\n",
    "\n",
    "    dataScaleSizeL_full.to_csv(\n",
    "        f\"{output_dir}/single_cell_before_redsea.csv\"\n",
    "    )\n",
    "    dataCompenScaleSizeL_full.to_csv(\n",
    "        f\"{output_dir}/single_cell_after_redsea.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "run_redsea(\n",
    "    \"data/TNP_pilot_cycif/TNP_pilot_cycif.ome_subset.tif\",\n",
    "    \"data/TNP_pilot_cycif/cellMask_subset.tif\",\n",
    "    \"data/TNP_pilot_cycif/markers.csv\",\n",
    "    ['CD4','CD163','CD68','anti_CD3','CD20','CD8a'],\n",
    "    \"test_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
